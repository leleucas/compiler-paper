bbox2offset.py
2022-04-20 13:56:34.669291: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-04-20 13:56:38.481961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30985 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3e:00.0, compute capability: 7.0
2022-04-20 13:56:39.417852: I tensorflow/compiler/xla/service/service.cc:171] XLA service 0x5602c06b17e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-04-20 13:56:39.417910: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-04-20 13:56:40.780036: I tensorflow/compiler/jit/xla_compilation_cache.cc:351] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Num GPUs Available:  1
time tensorflow: 12.536540031433105
time xla: 2.0620789527893066
delta2bbox.py
2022-04-20 13:57:00.601099: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-04-20 13:57:01.236898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30985 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3e:00.0, compute capability: 7.0
2022-04-20 13:57:02.150195: I tensorflow/compiler/xla/service/service.cc:171] XLA service 0x5623cd5d0b30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-04-20 13:57:02.150275: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-04-20 13:57:02.267042: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-04-20 13:57:02.508808: I tensorflow/compiler/jit/xla_compilation_cache.cc:351] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Num GPUs Available:  1
time costing origin: 40.02461862564087
time costing coderized: 1.8913931846618652
gen_base_anchors.py
2022-04-20 13:57:46.146483: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-04-20 13:57:46.736152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30985 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3e:00.0, compute capability: 7.0
2022-04-20 13:57:47.332058: I tensorflow/compiler/xla/service/service.cc:171] XLA service 0x5561db2b0fa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-04-20 13:57:47.332113: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-04-20 13:57:47.335936: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-04-20 13:57:47.427951: I tensorflow/compiler/jit/xla_compilation_cache.cc:351] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Num GPUs Available:  1
time tensorflow: 11.962856531143188
time xla: 1.6895291805267334
map_roi_levels.py
2022-04-20 13:58:02.877151: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-04-20 13:58:03.503150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30985 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3e:00.0, compute capability: 7.0
2022-04-20 13:58:04.078576: I tensorflow/compiler/xla/service/service.cc:171] XLA service 0x561d303a33e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-04-20 13:58:04.078634: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-04-20 13:58:04.091456: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-04-20 13:58:04.190789: I tensorflow/compiler/jit/xla_compilation_cache.cc:351] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Num GPUs Available:  1
time tensorflow: 7.93890643119812
time xla: 1.6617486476898193
valid_flags.py
Num GPUs Available:  1
Traceback (most recent call last):
  File "/home/xuping/compiler-paper/cases/tensorflow/valid_flags.py", line 73, in <module>
    assert np.allclose(fast_valid(*sargs).numpy(), valid_flags(*sargs).numpy())
  File "/home/xuping/.conda/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/xuping/.conda/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py", line 1129, in autograph_handler
    raise e.ag_error_metadata.to_exception(e)
TypeError: in user code:

    File "/home/xuping/compiler-paper/cases/tensorflow/valid_flags.py", line 49, in fast_valid  *
        valid_x[:valid_w] = 1

    TypeError: 'Tensor' object does not support item assignment

offset2bbox.py
2022-04-20 13:58:17.217778: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-04-20 13:58:17.904291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30985 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3e:00.0, compute capability: 7.0
Num GPUs Available:  1
Traceback (most recent call last):
  File "/home/xuping/compiler-paper/cases/tensorflow/offset2bbox.py", line 106, in <module>
    offset2bbox(*sargs_list).numpy(), fast_offset2bbox(*sargs_list).numpy())
  File "/home/xuping/compiler-paper/cases/tensorflow/offset2bbox.py", line 46, in offset2bbox
    pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w
TypeError: 'ResourceVariable' object does not support item assignment
tblr2bbox.py
2022-04-20 13:58:20.251283: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-04-20 13:58:20.892439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30985 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3e:00.0, compute capability: 7.0
Num GPUs Available:  1
Traceback (most recent call last):
  File "/home/xuping/compiler-paper/cases/tensorflow/tblr2bbox.py", line 132, in <module>
    ret = tblr2bboxes(*sargs)
  File "/home/xuping/compiler-paper/cases/tensorflow/tblr2bbox.py", line 95, in tblr2bboxes
    loc_decode[:, :2] *= h  # tb
TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment
